{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d38053be",
   "metadata": {},
   "outputs": [],
   "source": [
    "#导入所需模块\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7918c74",
   "metadata": {},
   "outputs": [],
   "source": [
    "def histogram_equalization(image):\n",
    "\n",
    "    # 计算直方图\n",
    "    hist, bins = np.histogram(image.flatten(), 256, [0, 256])\n",
    "\n",
    "    # 计算累积直方图\n",
    "    cdf = hist.cumsum()\n",
    "    cdf_normalized = cdf * float(hist.max()) / cdf.max()\n",
    "\n",
    "    # 创建映射表\n",
    "    cdf_m = np.ma.masked_equal(cdf, 0)\n",
    "    cdf_m = (cdf_m - cdf_m.min()) * 255 / (cdf_m.max() - cdf_m.min())\n",
    "    cdf = np.ma.filled(cdf_m, 0).astype('uint8')\n",
    "\n",
    "    # 应用映射表\n",
    "    equalized_image = cdf[image]\n",
    "\n",
    "    return equalized_image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e17e827a",
   "metadata": {},
   "source": [
    "# 导入训练图片"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f5da688",
   "metadata": {},
   "source": [
    "1、读取图片"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "269e6b06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 返回的是480张100*100的矩阵，和index\n",
    "listdir = os.listdir('./face_train')\n",
    "names = [d for d in listdir if not d.startswith('.')]\n",
    "images = []\n",
    "target = []\n",
    "for index,dir in enumerate(names):\n",
    "    for i in range(1, 11):\n",
    "        gray = cv2.imread('./face_train/%s/%d.jpg' % (dir, i))  # 三维图片\n",
    "        \n",
    "        #图像均衡化\n",
    "        gray_equalized = histogram_equalization(gray)\n",
    "        \n",
    "        gray_ = gray_equalized[:, :, 0]  # 二维数组\n",
    "        gray_ = cv2.resize(gray_, dsize=(100, 100))\n",
    "        images.append(gray_)\n",
    "        target.append(index)\n",
    "images = np.asarray(images)\n",
    "target = np.asarray(target)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28c0eec5",
   "metadata": {},
   "source": [
    "2、转换成矩阵"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "dbb39f6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#图像数据转换特征矩阵\n",
    "image_data = []\n",
    "\n",
    "for image in images:\n",
    "    #转换成一维的数组\n",
    "    data = image.flatten()\n",
    "    image_data.append(data)\n",
    "\n",
    "#print(image_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "44c37d63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "(200, 10000)\n"
     ]
    }
   ],
   "source": [
    "#转换为numpy数组\n",
    "X_train = np.array(image_data)\n",
    "y_train = target\n",
    "print(type(X_train))\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65149dda",
   "metadata": {},
   "source": [
    "# 导入测试向量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "cb0d822d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Yu Bin', 'Li Baoyan', 'Yu Ying', 'Yu Shaozhou', 'Yu Hong', 'Lv Hui', 'Wu Di', 'Dong Yini', 'Chen Jiayin', 'Wu Leru', 'Yu Di', 'Gao Yiqing', 'Liu Mingzhen', 'Li Xiufang', 'Chen Aijun', 'Jiang Letian', 'Yu Wei', 'Liu Jianhua', 'Zheng Ruojun', 'Dong Zhiyong']\n"
     ]
    }
   ],
   "source": [
    "listdir_test = os.listdir('./face_test')\n",
    "names_test = [d for d in listdir_test if not d.startswith('.')]\n",
    "print(names_test)\n",
    "images_test = []\n",
    "target_test = []\n",
    "for index_test,dir_test in enumerate(names_test):\n",
    "    for i in range(1, 31):\n",
    "        gray_test = cv2.imread('./face_test/%s/%d.jpg' % (dir_test, i))  # 三维图片\n",
    "        \n",
    "        #图像均衡化\n",
    "        gray_test_equalized = histogram_equalization(gray_test)\n",
    "        \n",
    "        gray_test_ = gray_test_equalized[:, :, 0]  # 二维数组\n",
    "        gray_test_ = cv2.resize(gray_test_, dsize=(100, 100))\n",
    "        images_test.append(gray_test_)\n",
    "        target_test.append(index_test)\n",
    "images_test = np.asarray(images_test)\n",
    "target_test = np.asarray(target_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "3f9bda43",
   "metadata": {},
   "outputs": [],
   "source": [
    "#图像数据转换特征矩阵\n",
    "image_data_test = []\n",
    "\n",
    "for image_test in images_test:\n",
    "    #转换成一维的数组\n",
    "    data_test = image_test.flatten()\n",
    "    image_data_test.append(data_test)\n",
    "\n",
    "#print(image_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "a81414cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "(600, 10000)\n"
     ]
    }
   ],
   "source": [
    "#转换为numpy数组\n",
    "X_test = np.array(image_data_test)\n",
    "y_test = target_test\n",
    "print(type(X_test))\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "138a38b7",
   "metadata": {},
   "source": [
    "# 对训练集进行预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "f1137dde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 对数据进行中心化，即每一列减去该列的均值\n",
    "X_train_centered = X_train - np.mean(X_train, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "970530d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 主成分数量\n",
    "k = 100\n",
    "# 对训练矩阵进行SVD\n",
    "U, S, Vt = np.linalg.svd(X_train_centered, full_matrices=False)\n",
    "# 选择前100个主成分\n",
    "X_train_pca = U[:, :k]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b525cd94",
   "metadata": {},
   "source": [
    "# SVM进行人脸识别"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "a2da72ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiClassSVM:\n",
    "    def __init__(self, X, y, k, C=1, tol=1e-5, max_iter=1000, learning_rate=0.01):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.k = k\n",
    "        self.C = C\n",
    "        self.tol = tol\n",
    "        self.max_iter = max_iter\n",
    "        self.learning_rate = learning_rate\n",
    "        self.n_samples, self.n_features = X.shape\n",
    "        self.n_classes = len(np.unique(y))\n",
    "        self.W = np.random.rand(self.n_features, self.n_classes)\n",
    "        self.b = np.random.rand(self.n_classes)\n",
    "        self.losses = []\n",
    "\n",
    "    def hinge_loss(self, X, y, W, b):\n",
    "        scores = np.dot(X, W) + b\n",
    "        correct_class_score = scores[np.arange(self.n_samples), y]\n",
    "        margins = np.maximum(0, scores - correct_class_score[:, np.newaxis] + 1)\n",
    "        margins[np.arange(self.n_samples), y] = 0\n",
    "        loss = np.sum(margins) / self.n_samples\n",
    "        return loss\n",
    "\n",
    "    def fit(self):\n",
    "        for i in range(self.max_iter):\n",
    "            scores = np.dot(self.X, self.W) + self.b\n",
    "            correct_class_score = scores[np.arange(self.n_samples), self.y]\n",
    "            margins = np.maximum(0, scores - correct_class_score[:, np.newaxis] + 1)\n",
    "            margins[np.arange(self.n_samples), self.y] = 0\n",
    "            margins[margins > 0] = 1\n",
    "            row_sum = np.sum(margins, axis=1)\n",
    "            margins[np.arange(self.n_samples), self.y] = -row_sum\n",
    "            dW = np.dot(self.X.T, margins) / self.n_samples\n",
    "            db = np.sum(margins, axis=0) / self.n_samples\n",
    "            dW += self.C * self.W\n",
    "            self.W -= self.learning_rate * dW\n",
    "            self.b -= self.learning_rate * db\n",
    "            loss = self.hinge_loss(self.X, self.y, self.W, self.b)\n",
    "            self.losses.append(loss)\n",
    "            if i % 10 == 0:\n",
    "                print('Iter %d / %d: loss %f' % (i, self.max_iter, loss))\n",
    "\n",
    "    def predict(self, X):\n",
    "        scores = np.dot(X, self.W) + self.b\n",
    "        y_pred = np.argmax(scores, axis=1)\n",
    "        return y_pred\n",
    "    \n",
    "    def score(self, X, y):\n",
    "        y_pred = self.predict(X)\n",
    "        accuracy = np.mean(y_pred == y)\n",
    "        return accuracy\n",
    "    \n",
    "    def get_params(self):\n",
    "        return self.W, self.b\n",
    "    \n",
    "    def get_losses(self):\n",
    "        return self.losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "c326e6e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 对数据进行中心化，即每一列减去该列的均值\n",
    "X_test_centered = X_test - np.mean(X_train, axis=0) # 注意这里使用的是训练数据的均值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "c4769d40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用训练集的Vt进行PCA\n",
    "X_test_pca = np.dot(X_test_centered, Vt.T[:, :k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "67666955",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 0 / 1000: loss 19.006978\n",
      "Iter 10 / 1000: loss 18.816622\n",
      "Iter 20 / 1000: loss 18.646529\n",
      "Iter 30 / 1000: loss 18.495096\n",
      "Iter 40 / 1000: loss 18.360496\n",
      "Iter 50 / 1000: loss 18.239245\n",
      "Iter 60 / 1000: loss 18.129940\n",
      "Iter 70 / 1000: loss 18.031121\n",
      "Iter 80 / 1000: loss 17.941900\n",
      "Iter 90 / 1000: loss 17.861305\n",
      "Iter 100 / 1000: loss 17.788459\n",
      "Iter 110 / 1000: loss 17.722751\n",
      "Iter 120 / 1000: loss 17.663385\n",
      "Iter 130 / 1000: loss 17.609771\n",
      "Iter 140 / 1000: loss 17.561319\n",
      "Iter 150 / 1000: loss 17.517543\n",
      "Iter 160 / 1000: loss 17.477954\n",
      "Iter 170 / 1000: loss 17.442149\n",
      "Iter 180 / 1000: loss 17.409769\n",
      "Iter 190 / 1000: loss 17.380484\n",
      "Iter 200 / 1000: loss 17.354000\n",
      "Iter 210 / 1000: loss 17.330048\n",
      "Iter 220 / 1000: loss 17.308386\n",
      "Iter 230 / 1000: loss 17.288795\n",
      "Iter 240 / 1000: loss 17.271078\n",
      "Iter 250 / 1000: loss 17.255055\n",
      "Iter 260 / 1000: loss 17.240564\n",
      "Iter 270 / 1000: loss 17.227458\n",
      "Iter 280 / 1000: loss 17.215606\n",
      "Iter 290 / 1000: loss 17.204887\n",
      "Iter 300 / 1000: loss 17.195193\n",
      "Iter 310 / 1000: loss 17.186425\n",
      "Iter 320 / 1000: loss 17.178496\n",
      "Iter 330 / 1000: loss 17.171326\n",
      "Iter 340 / 1000: loss 17.164841\n",
      "Iter 350 / 1000: loss 17.158976\n",
      "Iter 360 / 1000: loss 17.153671\n",
      "Iter 370 / 1000: loss 17.148874\n",
      "Iter 380 / 1000: loss 17.144536\n",
      "Iter 390 / 1000: loss 17.140612\n",
      "Iter 400 / 1000: loss 17.137064\n",
      "Iter 410 / 1000: loss 17.133855\n",
      "Iter 420 / 1000: loss 17.130953\n",
      "Iter 430 / 1000: loss 17.128328\n",
      "Iter 440 / 1000: loss 17.125954\n",
      "Iter 450 / 1000: loss 17.123807\n",
      "Iter 460 / 1000: loss 17.121866\n",
      "Iter 470 / 1000: loss 17.120110\n",
      "Iter 480 / 1000: loss 17.118522\n",
      "Iter 490 / 1000: loss 17.117086\n",
      "Iter 500 / 1000: loss 17.115787\n",
      "Iter 510 / 1000: loss 17.114612\n",
      "Iter 520 / 1000: loss 17.113550\n",
      "Iter 530 / 1000: loss 17.112589\n",
      "Iter 540 / 1000: loss 17.111721\n",
      "Iter 550 / 1000: loss 17.110935\n",
      "Iter 560 / 1000: loss 17.110224\n",
      "Iter 570 / 1000: loss 17.109581\n",
      "Iter 580 / 1000: loss 17.109000\n",
      "Iter 590 / 1000: loss 17.108474\n",
      "Iter 600 / 1000: loss 17.107999\n",
      "Iter 610 / 1000: loss 17.107569\n",
      "Iter 620 / 1000: loss 17.107180\n",
      "Iter 630 / 1000: loss 17.106829\n",
      "Iter 640 / 1000: loss 17.106511\n",
      "Iter 650 / 1000: loss 17.106223\n",
      "Iter 660 / 1000: loss 17.105963\n",
      "Iter 670 / 1000: loss 17.105728\n",
      "Iter 680 / 1000: loss 17.105515\n",
      "Iter 690 / 1000: loss 17.105322\n",
      "Iter 700 / 1000: loss 17.105148\n",
      "Iter 710 / 1000: loss 17.104991\n",
      "Iter 720 / 1000: loss 17.104849\n",
      "Iter 730 / 1000: loss 17.104720\n",
      "Iter 740 / 1000: loss 17.104604\n",
      "Iter 750 / 1000: loss 17.104498\n",
      "Iter 760 / 1000: loss 17.104403\n",
      "Iter 770 / 1000: loss 17.104317\n",
      "Iter 780 / 1000: loss 17.104239\n",
      "Iter 790 / 1000: loss 17.104169\n",
      "Iter 800 / 1000: loss 17.104105\n",
      "Iter 810 / 1000: loss 17.104047\n",
      "Iter 820 / 1000: loss 17.103995\n",
      "Iter 830 / 1000: loss 17.103948\n",
      "Iter 840 / 1000: loss 17.103906\n",
      "Iter 850 / 1000: loss 17.103867\n",
      "Iter 860 / 1000: loss 17.103832\n",
      "Iter 870 / 1000: loss 17.103801\n",
      "Iter 880 / 1000: loss 17.103772\n",
      "Iter 890 / 1000: loss 17.103746\n",
      "Iter 900 / 1000: loss 17.103723\n",
      "Iter 910 / 1000: loss 17.103702\n",
      "Iter 920 / 1000: loss 17.103683\n",
      "Iter 930 / 1000: loss 17.103666\n",
      "Iter 940 / 1000: loss 17.103650\n",
      "Iter 950 / 1000: loss 17.103636\n",
      "Iter 960 / 1000: loss 17.103623\n",
      "Iter 970 / 1000: loss 17.103612\n",
      "Iter 980 / 1000: loss 17.103601\n",
      "Iter 990 / 1000: loss 17.103592\n"
     ]
    }
   ],
   "source": [
    "svm = MultiClassSVM(X_train_pca, y_train, k)\n",
    "svm.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "9dcea7d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of true predictions: 540\n"
     ]
    }
   ],
   "source": [
    "y_pred = svm.predict(X_test_pca)\n",
    "true_count = np.sum(y_pred == y_test)\n",
    "print('Number of true predictions:', true_count)\n",
    "test_accuracy = svm.score(X_test_pca, y_test)  # 注意这里使用的是PCA处理后的测试数据\n",
    "print('Test accuracy:', test_accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
